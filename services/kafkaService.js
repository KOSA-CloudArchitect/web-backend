const { Kafka } = require('kafkajs');
const { v4: uuidv4 } = require('uuid');
const logger = require('../config/logger');

class KafkaService {
  constructor() {
    this.kafka = null;
    this.producer = null;
    this.consumer = null;
    this.isConnected = false;
    this.messageHandlers = new Map();
  }

  /**
   * Kafka í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
   */
  async initialize() {
    try {
      const brokers = (process.env.KAFKA_BROKERS || 'localhost:9092').split(',');
      const clientId = process.env.KAFKA_CLIENT_ID || 'kosa-backend';
      
      this.kafka = new Kafka({
        clientId,
        brokers,
        retry: {
          initialRetryTime: 100,
          retries: 8
        },
        // SSL ì„¤ì • (í™˜ê²½ ë³€ìˆ˜ë¡œ ì œì–´)
        ...(process.env.KAFKA_SSL_ENABLED === 'true' && {
          ssl: {
            rejectUnauthorized: false
          }
        }),
        // SASL ì¸ì¦ ì„¤ì • (í™˜ê²½ ë³€ìˆ˜ë¡œ ì œì–´)
        ...(process.env.KAFKA_SASL_ENABLED === 'true' && {
          sasl: {
            mechanism: process.env.KAFKA_SASL_MECHANISM || 'plain',
            username: process.env.KAFKA_SASL_USERNAME,
            password: process.env.KAFKA_SASL_PASSWORD
          }
        })
      });

      // Producer ì´ˆê¸°í™”
      this.producer = this.kafka.producer({
        compression: 'lz4',
        batch: {
          size: 16384,
          lingerMs: 10
        },
        retry: {
          initialRetryTime: 100,
          retries: 5
        }
      });

      // Consumer ì´ˆê¸°í™”
      this.consumer = this.kafka.consumer({
        groupId: process.env.KAFKA_GROUP_ID || 'kosa-backend-group',
        sessionTimeout: 30000,
        heartbeatInterval: 3000,
        maxWaitTimeInMs: 5000
      });

      logger.info('Kafka í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” ì™„ë£Œ');
    } catch (error) {
      logger.error('Kafka í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” ì‹¤íŒ¨:', error);
      throw error;
    }
  }

  /**
   * Kafka Producer ì—°ê²°
   */
  async connectProducer() {
    try {
      if (!this.producer) {
        throw new Error('Producerê°€ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.');
      }

      await this.producer.connect();
      logger.info('âœ… Kafka Producer ì—°ê²° ì„±ê³µ');
    } catch (error) {
      logger.error('âŒ Kafka Producer ì—°ê²° ì‹¤íŒ¨:', error);
      throw error;
    }
  }

  /**
   * Kafka Consumer ì—°ê²° ë° í† í”½ êµ¬ë…
   */
  async connectConsumer(topics = []) {
    try {
      if (!this.consumer) {
        throw new Error('Consumerê°€ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.');
      }

      await this.consumer.connect();
      
      if (topics.length > 0) {
        await this.consumer.subscribe({
          topics,
          fromBeginning: false
        });
      }

      logger.info('âœ… Kafka Consumer ì—°ê²° ì„±ê³µ');
      this.isConnected = true;
    } catch (error) {
      logger.error('âŒ Kafka Consumer ì—°ê²° ì‹¤íŒ¨:', error);
      throw error;
    }
  }

  /**
   * ë©”ì‹œì§€ í•¸ë“¤ëŸ¬ ë“±ë¡
   */
  registerMessageHandler(topic, handler) {
    this.messageHandlers.set(topic, handler);
    logger.info(`ë©”ì‹œì§€ í•¸ë“¤ëŸ¬ ë“±ë¡: ${topic}`);
  }

  /**
   * Consumer ë©”ì‹œì§€ ì²˜ë¦¬ ì‹œì‘
   */
  async startConsumer() {
    try {
      if (!this.consumer || !this.isConnected) {
        throw new Error('Consumerê°€ ì—°ê²°ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.');
      }

      await this.consumer.run({
        eachMessage: async ({ topic, partition, message }) => {
          try {
            const data = JSON.parse(message.value.toString());
            const headers = message.headers || {};
            
            logger.info(`ğŸ“¨ Kafka ë©”ì‹œì§€ ìˆ˜ì‹  [${topic}]:`, {
              partition,
              offset: message.offset,
              key: message.key?.toString(),
              timestamp: message.timestamp
            });

            // ë“±ë¡ëœ í•¸ë“¤ëŸ¬ ì‹¤í–‰
            const handler = this.messageHandlers.get(topic);
            if (handler) {
              await handler(data, { topic, partition, message, headers });
            } else {
              logger.warn(`í•¸ë“¤ëŸ¬ê°€ ë“±ë¡ë˜ì§€ ì•Šì€ í† í”½: ${topic}`);
            }

          } catch (error) {
            logger.error(`âŒ Kafka ë©”ì‹œì§€ ì²˜ë¦¬ ì˜¤ë¥˜ [${topic}]:`, error);
          }
        }
      });

      logger.info('âœ… Kafka Consumer ë©”ì‹œì§€ ì²˜ë¦¬ ì‹œì‘');
    } catch (error) {
      logger.error('âŒ Kafka Consumer ì‹œì‘ ì‹¤íŒ¨:', error);
      throw error;
    }
  }

  /**
   * ìƒí’ˆ ê²€ìƒ‰ ìš”ì²­ ì „ì†¡
   */
  async sendProductSearchRequest(searchQuery, options = {}) {
    const messageId = `search_${Date.now()}_${uuidv4().slice(0, 8)}`;
    
    const searchRequest = {
      messageId,
      requestType: 'product_search',
      query: searchQuery,
      options: {
        limit: 20,
        includeReviews: false,
        ...options
      },
      timestamp: new Date().toISOString(),
      metadata: {
        source: 'web_app',
        userId: options.userId || 'anonymous'
      }
    };

    try {
      await this.producer.send({
        topic: 'product-search-requests',
        messages: [{
          key: searchQuery,
          value: JSON.stringify(searchRequest),
          headers: {
            'request-type': 'product_search',
            'message-id': messageId
          }
        }]
      });

      logger.info(`ğŸ“¤ ìƒí’ˆ ê²€ìƒ‰ ìš”ì²­ ì „ì†¡ [${messageId}]:`, searchQuery);
      return messageId;
    } catch (error) {
      logger.error('âŒ ìƒí’ˆ ê²€ìƒ‰ ìš”ì²­ ì „ì†¡ ì‹¤íŒ¨:', error);
      throw error;
    }
  }

  /**
   * ì‹¤ì‹œê°„ ë¶„ì„ ìš”ì²­ ì „ì†¡
   */
  async sendAnalysisRequest(productId, requestType = 'realtime', options = {}) {
    const requestId = uuidv4();
    const messageId = `analysis_${Date.now()}_${requestId.slice(0, 8)}`;

    const analysisRequest = {
      messageId,
      requestId,
      productId,
      requestType,
      options: {
        includeKeywords: true,
        includeSentiment: true,
        includeTrends: true,
        ...options
      },
      priority: requestType === 'realtime' ? 'high' : 'medium',
      timestamp: new Date().toISOString(),
      metadata: {
        source: 'web_app',
        userId: options.userId || 'anonymous'
      }
    };

    try {
      await this.producer.send({
        topic: 'analysis-requests',
        messages: [{
          key: productId,
          value: JSON.stringify(analysisRequest),
          headers: {
            'request-type': requestType,
            'priority': analysisRequest.priority,
            'request-id': requestId
          }
        }]
      });

      logger.info(`ğŸ“¤ ë¶„ì„ ìš”ì²­ ì „ì†¡ [${requestId}]:`, productId);
      return requestId;
    } catch (error) {
      logger.error('âŒ ë¶„ì„ ìš”ì²­ ì „ì†¡ ì‹¤íŒ¨:', error);
      throw error;
    }
  }

  /**
   * ê´€ì‹¬ ìƒí’ˆ ë“±ë¡ ìš”ì²­ ì „ì†¡
   */
  async sendWatchlistRequest(productId, userId, options = {}) {
    const messageId = `watchlist_${Date.now()}_${uuidv4().slice(0, 8)}`;

    const watchlistRequest = {
      messageId,
      requestType: 'watchlist_add',
      productId,
      userId,
      options: {
        frequency: 'daily',
        notifications: true,
        priceAlerts: true,
        ...options
      },
      timestamp: new Date().toISOString(),
      metadata: {
        source: 'web_app'
      }
    };

    try {
      await this.producer.send({
        topic: 'watchlist-requests',
        messages: [{
          key: `${userId}_${productId}`,
          value: JSON.stringify(watchlistRequest),
          headers: {
            'request-type': 'watchlist_add',
            'user-id': userId,
            'product-id': productId
          }
        }]
      });

      logger.info(`ğŸ“¤ ê´€ì‹¬ ìƒí’ˆ ë“±ë¡ ìš”ì²­ ì „ì†¡ [${messageId}]:`, { productId, userId });
      return messageId;
    } catch (error) {
      logger.error('âŒ ê´€ì‹¬ ìƒí’ˆ ë“±ë¡ ìš”ì²­ ì „ì†¡ ì‹¤íŒ¨:', error);
      throw error;
    }
  }

  /**
   * ë°°ì¹˜ ë¶„ì„ ì‘ì—… ì „ì†¡
   */
  async sendBatchJob(productIds, schedule = 'daily', options = {}) {
    const jobId = uuidv4();
    const messageId = `batch_${Date.now()}_${jobId.slice(0, 8)}`;

    const batchJob = {
      messageId,
      jobId,
      jobType: 'batch_analysis',
      productIds,
      schedule,
      options: {
        frequency: schedule,
        notifications: true,
        ...options
      },
      timestamp: new Date().toISOString(),
      metadata: {
        userId: options.userId || 'system',
        createdBy: 'api'
      }
    };

    try {
      await this.producer.send({
        topic: 'batch-jobs',
        messages: [{
          key: jobId,
          value: JSON.stringify(batchJob),
          headers: {
            'job-type': 'batch_analysis',
            'job-id': jobId
          }
        }]
      });

      logger.info(`ğŸ“¤ ë°°ì¹˜ ì‘ì—… ì „ì†¡ [${jobId}]:`, `${productIds.length}ê°œ ìƒí’ˆ`);
      return jobId;
    } catch (error) {
      logger.error('âŒ ë°°ì¹˜ ì‘ì—… ì „ì†¡ ì‹¤íŒ¨:', error);
      throw error;
    }
  }

  /**
   * ì—°ê²° í•´ì œ
   */
  async disconnect() {
    try {
      if (this.producer) {
        await this.producer.disconnect();
        logger.info('âœ… Kafka Producer ì—°ê²° í•´ì œ');
      }

      if (this.consumer) {
        await this.consumer.disconnect();
        logger.info('âœ… Kafka Consumer ì—°ê²° í•´ì œ');
      }

      this.isConnected = false;
    } catch (error) {
      logger.error('âŒ Kafka ì—°ê²° í•´ì œ ì‹¤íŒ¨:', error);
      throw error;
    }
  }

  /**
   * ì—°ê²° ìƒíƒœ í™•ì¸
   */
  isProducerConnected() {
    return this.producer && this.isConnected;
  }

  isConsumerConnected() {
    return this.consumer && this.isConnected;
  }
}

// ì‹±ê¸€í†¤ ì¸ìŠ¤í„´ìŠ¤
const kafkaService = new KafkaService();

module.exports = kafkaService;