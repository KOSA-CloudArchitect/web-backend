const airflowClient = require('./airflowClient');
// const kafkaProducer = require('./kafkaProducer');
const cacheService = require('./cacheService');
const { Sentry } = require('../config/sentry');
const RedisAnalysisRequest = require('../models/redisAnalysisRequest');
const RedisAnalysisQueue = require('../models/redisAnalysisQueue');
const MongoAnalysisResult = require('../models/mongoAnalysisResult');
const websocketService = require('./websocketService');

/**
 * ë¶„ì„ ì„œë¹„ìŠ¤
 * Airflow DAG íŠ¸ë¦¬ê±° ë° ë¶„ì„ ìš”ì²­ ê´€ë¦¬
 */
class AnalysisService {
  constructor() {
    this.analysisCache = new Map(); // ì§„í–‰ ì¤‘ì¸ ë¶„ì„ ìš”ì²­ ìºì‹œ (ë ˆê±°ì‹œ)
    this.redisRequest = new RedisAnalysisRequest();
    this.redisQueue = new RedisAnalysisQueue();
    this.mongoResult = new MongoAnalysisResult();
  }

  /**
   * ë‹¨ì¼ ìƒí’ˆ ë¶„ì„ ìš”ì²­
   * @param {Object} params - ë¶„ì„ ìš”ì²­ íŒŒë¼ë¯¸í„°
   * @param {string} params.productId - ìƒí’ˆ ID
   * @param {string} params.productUrl - ìƒí’ˆ URL
   * @param {string} params.userId - ì‚¬ìš©ì ID
   * @returns {Promise<Object>} ë¶„ì„ ìš”ì²­ ê²°ê³¼
   */
  async requestSingleProductAnalysis(params) {
    try {
      const { productId, productUrl, userId } = params;
      
      console.log(`ğŸ” Starting single product analysis request:`, {
        productId,
        userId,
        hasUrl: !!productUrl,
      });

      // 1. ìƒí’ˆ ë¶„ì„ ë½ í™•ì¸ ë° íšë“ ì‹œë„
      const existingLock = await this.redisQueue.checkLock(productId);
      if (existingLock) {
        // ê¸°ì¡´ ë¶„ì„ì´ ì§„í–‰ ì¤‘ì¸ ê²½ìš° íì— ì¶”ê°€
        const existingRequest = await this.redisRequest.findByTaskId(existingLock);
        if (existingRequest) {
          console.log(`âš¡ Analysis in progress for product ${productId}, adding to queue`);
          
          // íì— ì‚¬ìš©ì ì¶”ê°€
          const queueInfo = await this.redisQueue.addToQueue(productId, userId, existingLock, 'realtime');
          
          return {
            status: 'queued',
            taskId: existingLock,
            dagRunId: existingRequest.dagRunId,
            dagId: existingRequest.dagId,
            message: 'Added to analysis queue',
            queuePosition: queueInfo.userCount,
            estimatedCompletion: queueInfo.estimatedCompletion,
            cached: true,
          };
        }
      }

      // 2. Airflow DAG íŠ¸ë¦¬ê±°
      const dagRun = await airflowClient.triggerSingleProductAnalysis({
        productId,
        productUrl,
        userId,
      });

      const taskId = `single_${productId}_${Date.now()}`;

      // 3. Redis ë¶„ì„ ìš”ì²­ ìƒì„±
      const analysisRequest = await this.redisRequest.create({
        taskId,
        userId,
        productId,
        requestType: 'realtime',
        dagId: dagRun.dagId,
        dagRunId: dagRun.dagRunId,
        metadata: {
          productUrl,
          triggerType: 'single_product',
        },
      });

      // 4. ë¶„ì„ ë½ íšë“
      const lockAcquired = await this.redisQueue.acquireLock(productId, taskId);
      if (!lockAcquired) {
        // ë½ íšë“ ì‹¤íŒ¨ ì‹œ ê¸°ì¡´ ë¶„ì„ì— í ì¶”ê°€
        await this.redisRequest.delete(taskId);
        const currentLock = await this.redisQueue.checkLock(productId);
        if (currentLock) {
          const queueInfo = await this.redisQueue.addToQueue(productId, userId, currentLock, 'realtime');
          return {
            status: 'queued',
            taskId: currentLock,
            message: 'Added to existing analysis queue',
            queuePosition: queueInfo.userCount,
            estimatedCompletion: queueInfo.estimatedCompletion,
          };
        }
      }

      // 5. í ìƒì„± (ì²« ë²ˆì§¸ ì‚¬ìš©ì)
      await this.redisQueue.addToQueue(productId, userId, taskId, 'realtime');

      // 6. Kafkaë¡œ ë¶„ì„ ì‹œì‘ ë©”ì‹œì§€ ì „ì†¡ (í˜„ì¬ ì‚¬ìš©í•˜ì§€ ì•ŠìŒ)
      // try {
      //   await kafkaProducer.sendMessage('analysis-requests', {
      //     type: 'single_product_analysis_started',
      //     taskId,
      //     dagRunId: dagRun.dagRunId,
      //     productId,
      //     userId,
      //     timestamp: new Date().toISOString(),
      //   });
      // } catch (kafkaError) {
      //   console.warn('âš ï¸ Failed to send Kafka message:', kafkaError);
      //   // Kafka ì‹¤íŒ¨ëŠ” ì „ì²´ í”„ë¡œì„¸ìŠ¤ë¥¼ ì¤‘ë‹¨ì‹œí‚¤ì§€ ì•ŠìŒ
      // }

      console.log(`âœ… Single product analysis triggered successfully:`, {
        taskId,
        dagRunId: dagRun.dagRunId,
        productId,
      });

      // WebSocketìœ¼ë¡œ ë¶„ì„ ì‹œì‘ ì•Œë¦¼
      websocketService.sendAnalysisUpdate(taskId, {
        status: 'triggered',
        type: 'analysis_started',
        message: 'ìƒí’ˆ ë¶„ì„ì´ ì‹œì‘ë˜ì—ˆìŠµë‹ˆë‹¤.',
        productId,
        userId,
        dagRunId: dagRun.dagRunId,
        estimatedTime: 'ì•½ 2-5ë¶„ ì†Œìš” ì˜ˆì •'
      });

      // ì‚¬ìš©ì ë£¸ì—ë„ ì•Œë¦¼
      if (userId) {
        await websocketService.emitToRoom(`user:${userId}`, 'analysis-started', {
          taskId,
          productId,
          message: 'ìƒí’ˆ ë¶„ì„ì„ ì‹œì‘í–ˆìŠµë‹ˆë‹¤.',
          dagRunId: dagRun.dagRunId
        });
      }

      return {
        status: 'triggered',
        taskId,
        dagRunId: dagRun.dagRunId,
        dagId: dagRun.dagId,
        executionDate: dagRun.executionDate,
        message: 'Analysis started successfully',
      };

    } catch (error) {
      console.error('âŒ Failed to request single product analysis:', error);
      
      Sentry.withScope((scope) => {
        scope.setTag('analysis_request_failed', true);
        scope.setContext('analysis_request', {
          type: 'single_product',
          productId: params.productId,
          userId: params.userId,
        });
        Sentry.captureException(error);
      });

      throw error;
    }
  }

  /**
   * Redis ê¸°ë°˜ ë¶„ì„ ìƒíƒœ ì¡°íšŒ
   * @param {string} taskId - ì‘ì—… ID
   * @returns {Promise<Object>} ë¶„ì„ ìƒíƒœ ì •ë³´
   */
  async getAnalysisStatusByTaskId(taskId) {
    try {
      console.log(`ğŸ” Checking analysis status for task: ${taskId}`);
      
      const analysisRequest = await this.redisRequest.findByTaskId(taskId);
      if (!analysisRequest) {
        throw new Error('Analysis request not found');
      }
      
      // Airflow DAG ìƒíƒœ í™•ì¸ (ì§„í–‰ ì¤‘ì¸ ê²½ìš°)
      if (['pending', 'processing'].includes(analysisRequest.status) && 
          analysisRequest.dagId && analysisRequest.dagRunId) {
        
        try {
          const dagStatus = await airflowClient.getDagRunStatus(
            analysisRequest.dagId, 
            analysisRequest.dagRunId
          );
          
          // DAG ìƒíƒœì— ë”°ë¥¸ ë¶„ì„ ìš”ì²­ ìƒíƒœ ì—…ë°ì´íŠ¸
          let newStatus = analysisRequest.status;
          if (dagStatus.state === 'success') {
            newStatus = 'completed';
          } else if (dagStatus.state === 'failed') {
            newStatus = 'failed';
          } else if (dagStatus.state === 'running') {
            newStatus = 'processing';
          }
          
          // ìƒíƒœê°€ ë³€ê²½ëœ ê²½ìš° ì—…ë°ì´íŠ¸
          if (newStatus !== analysisRequest.status) {
            await this.redisRequest.update(taskId, { status: newStatus });
            analysisRequest.status = newStatus;
            
            // ì™„ë£Œëœ ê²½ìš° ë½ í•´ì œ
            if (newStatus === 'completed') {
              await this.redisQueue.releaseLock(analysisRequest.productId, taskId);
              await this.redisQueue.completeQueue(analysisRequest.productId);
            } else if (newStatus === 'failed') {
              await this.redisQueue.releaseLock(analysisRequest.productId, taskId);
              await this.redisRequest.markAsFailed(taskId, 'DAG execution failed');
            }
          }
          
        } catch (dagError) {
          console.warn(`âš ï¸ Failed to check DAG status: ${dagError.message}`);
        }
      }
      
      // í ì •ë³´ ì¡°íšŒ
      const queueInfo = await this.redisQueue.getQueue(analysisRequest.productId);
      
      return {
        taskId: analysisRequest.taskId,
        status: analysisRequest.status,
        progress: analysisRequest.progress,
        currentStep: analysisRequest.currentStep,
        totalReviews: analysisRequest.totalReviews,
        processedReviews: analysisRequest.processedReviews,
        errorMessage: analysisRequest.errorMessage,
        createdAt: analysisRequest.createdAt,
        startedAt: analysisRequest.startedAt,
        completedAt: analysisRequest.completedAt,
        dagId: analysisRequest.dagId,
        dagRunId: analysisRequest.dagRunId,
        queueInfo: queueInfo ? {
          position: queueInfo.queueData.findIndex(user => user.taskId === taskId) + 1,
          totalUsers: queueInfo.userCount,
          estimatedCompletion: queueInfo.estimatedCompletion,
        } : null,
      };
      
    } catch (error) {
      console.error('âŒ Failed to get analysis status:', error);
      
      Sentry.withScope((scope) => {
        scope.setTag('analysis_status_check_failed', true);
        scope.setContext('analysis_status_check', { taskId });
        Sentry.captureException(error);
      });
      
      throw error;
    }
  }

  /**
   * ìƒí’ˆ ê¸°ë°˜ ë¶„ì„ ìƒíƒœ ì¡°íšŒ
   * @param {string} productId - ìƒí’ˆ ID
   * @param {string} userId - ì‚¬ìš©ì ID
   * @returns {Promise<Object|null>} ë¶„ì„ ìƒíƒœ ì •ë³´
   */
  async getAnalysisStatusByProduct(productId, userId) {
    try {
      // í˜„ì¬ ì§„í–‰ ì¤‘ì¸ ë¶„ì„ í™•ì¸
      const activeLock = await this.redisQueue.checkLock(productId);
      if (activeLock) {
        const analysisRequest = await this.redisRequest.findByTaskId(activeLock);
        if (analysisRequest) {
          return await this.getAnalysisStatusByTaskId(activeLock);
        }
      }
      
      // ì‚¬ìš©ìì˜ ìµœê·¼ ë¶„ì„ ìš”ì²­ í™•ì¸
      const activeRequests = await this.redisRequest.findActiveByUserId(userId);
      const productRequest = activeRequests.find(req => req.productId === productId);
      
      if (productRequest) {
        return await this.getAnalysisStatusByTaskId(productRequest.taskId);
      }
      
      return null;
      
    } catch (error) {
      console.error('âŒ Failed to get product analysis status:', error);
      throw error;
    }
  }

  /**
   * ë¶„ì„ ê²°ê³¼ ì²˜ë¦¬ ë° MongoDB ì €ì¥
   * @param {string} taskId - ì‘ì—… ID
   * @param {Object} result - ë¶„ì„ ê²°ê³¼ ë°ì´í„°
   * @returns {Promise<Object>} ì €ì¥ëœ ë¶„ì„ ê²°ê³¼
   */
  async processAnalysisResult(taskId, result) {
    try {
      console.log(`ğŸ“Š Processing analysis result for task: ${taskId}`);
      
      // Redisì—ì„œ ë¶„ì„ ìš”ì²­ ì •ë³´ ì¡°íšŒ
      const analysisRequest = await this.redisRequest.findByTaskId(taskId);
      if (!analysisRequest) {
        throw new Error(`Analysis request not found for task: ${taskId}`);
      }

      // ë¶„ì„ ê²°ê³¼ ë°ì´í„° ì¤€ë¹„
      const analysisResultData = {
        productId: analysisRequest.productId,
        taskId: taskId,
        sentiment: {
          positive: result.sentiment?.positive || 0,
          negative: result.sentiment?.negative || 0,
          neutral: result.sentiment?.neutral || 0,
        },
        summary: result.summary || '',
        totalReviews: result.totalReviews || 0,
        averageRating: result.averageRating,
        processingTime: result.processingTime || this.calculateProcessingTime(analysisRequest),
        keywords: result.keywords || [],
        reviewDistribution: result.reviewDistribution || {},
        crawledAt: result.crawledAt,
        analysisVersion: result.analysisVersion || '1.0.0',
        sourceUrl: analysisRequest.metadata?.productUrl,
        userId: analysisRequest.userId,
        requestType: analysisRequest.requestType,
      };

      // MongoDBì— ë¶„ì„ ê²°ê³¼ ì €ì¥
      const savedResult = await this.mongoResult.create(analysisResultData);
      
      // Redis ë¶„ì„ ìš”ì²­ ì™„ë£Œ ì²˜ë¦¬
      await this.redisRequest.markAsCompleted(taskId, {
        mongoId: savedResult._id,
        completedAt: new Date().toISOString(),
      });

      // ë¶„ì„ ë½ í•´ì œ ë° í ì™„ë£Œ ì²˜ë¦¬
      await this.redisQueue.releaseLock(analysisRequest.productId, taskId);
      await this.redisQueue.completeQueue(analysisRequest.productId);

      console.log(`âœ… Analysis result processed and saved: ${savedResult._id}`);

      // WebSocketìœ¼ë¡œ ì‹¤ì‹œê°„ ë¶„ì„ ì™„ë£Œ ì•Œë¦¼
      websocketService.sendAnalysisUpdate(taskId, {
        status: 'completed',
        type: 'result_saved',
        message: 'ë¶„ì„ ê²°ê³¼ê°€ MongoDBì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.',
        productId: analysisRequest.productId,
        userId: analysisRequest.userId,
        result: {
          sentiment: analysisResultData.sentiment,
          summary: analysisResultData.summary,
          totalReviews: analysisResultData.totalReviews,
          averageRating: analysisResultData.averageRating,
          keywords: analysisResultData.keywords
        },
        mongoId: savedResult._id
      });

      // ìƒí’ˆë³„ ë£¸ì—ë„ ì•Œë¦¼ (ìƒí’ˆì„ ë³´ê³  ìˆëŠ” ë‹¤ë¥¸ ì‚¬ìš©ìë“¤ì—ê²Œ)
      await websocketService.emitToRoom(`product:${analysisRequest.productId}`, 'analysis-completed', {
        productId: analysisRequest.productId,
        taskId: taskId,
        message: 'ìƒˆë¡œìš´ ë¶„ì„ ê²°ê³¼ê°€ ì—…ë°ì´íŠ¸ë˜ì—ˆìŠµë‹ˆë‹¤.',
        summary: analysisResultData.summary,
        sentiment: analysisResultData.sentiment
      });

      // ì‚¬ìš©ìë³„ ë£¸ì—ë„ ì•Œë¦¼
      if (analysisRequest.userId) {
        await websocketService.emitToRoom(`user:${analysisRequest.userId}`, 'my-analysis-completed', {
          taskId: taskId,
          productId: analysisRequest.productId,
          message: 'ìš”ì²­í•˜ì‹  ë¶„ì„ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.',
          result: {
            sentiment: analysisResultData.sentiment,
            summary: analysisResultData.summary,
            totalReviews: analysisResultData.totalReviews
          }
        });
      }
      
      return savedResult;

    } catch (error) {
      console.error('âŒ Failed to process analysis result:', error);
      
      // ì‹¤íŒ¨ ì‹œ Redis ìƒíƒœ ì—…ë°ì´íŠ¸
      await this.redisRequest.markAsFailed(taskId, error.message);
      
      Sentry.withScope((scope) => {
        scope.setTag('analysis_result_processing_failed', true);
        scope.setContext('analysis_result_processing', { taskId });
        Sentry.captureException(error);
      });
      
      throw error;
    }
  }

  /**
   * ë¶„ì„ ì²˜ë¦¬ ì‹œê°„ ê³„ì‚°
   * @param {Object} analysisRequest - ë¶„ì„ ìš”ì²­ ì •ë³´
   * @returns {number} ì²˜ë¦¬ ì‹œê°„ (ì´ˆ)
   */
  calculateProcessingTime(analysisRequest) {
    if (!analysisRequest.startedAt) {
      return 0;
    }
    
    const startTime = new Date(analysisRequest.startedAt);
    const endTime = new Date();
    return Math.round((endTime - startTime) / 1000);
  }

  /**
   * ë¶„ì„ ê²°ê³¼ ì¡°íšŒ (MongoDBì—ì„œ)
   * @param {string} productId - ìƒí’ˆ ID
   * @returns {Promise<Object|null>} ë¶„ì„ ê²°ê³¼
   */
  async getAnalysisResult(productId) {
    try {
      console.log(`ğŸ” Getting analysis result for product: ${productId}`);
      
      // MongoDBì—ì„œ ìµœì‹  ë¶„ì„ ê²°ê³¼ ì¡°íšŒ
      const result = await this.mongoResult.findLatestByProductId(productId);
      
      if (!result) {
        return null;
      }

      // í”„ë¡ íŠ¸ì—”ë“œ í˜•ì‹ìœ¼ë¡œ ë³€í™˜
      return {
        productId: result.productId,
        sentiment: {
          positive: result.sentimentPositive,
          negative: result.sentimentNegative,
          neutral: result.sentimentNeutral,
        },
        summary: result.summary,
        keywords: result.keywords?.map(k => k.keyword) || [],
        totalReviews: result.totalReviews,
        averageRating: result.averageRating,
        processingTime: result.processingTime,
        createdAt: result.createdAt,
        updatedAt: result.updatedAt,
      };

    } catch (error) {
      console.error('âŒ Failed to get analysis result:', error);
      throw error;
    }
  }

  /**
   * ì‚¬ìš©ìì˜ ë¶„ì„ ê²°ê³¼ ëª©ë¡ ì¡°íšŒ
   * @param {string} userId - ì‚¬ìš©ì ID
   * @param {number} page - í˜ì´ì§€ ë²ˆí˜¸
   * @param {number} limit - í˜ì´ì§€ë‹¹ ê°œìˆ˜
   * @returns {Promise<Object>} ë¶„ì„ ê²°ê³¼ ëª©ë¡ê³¼ í˜ì´ì§• ì •ë³´
   */
  async getUserAnalysisResults(userId, page = 1, limit = 10) {
    try {
      console.log(`ğŸ” Getting analysis results for user: ${userId}`);
      
      const results = await this.mongoResult.findByUserId(userId, page, limit);
      
      // í”„ë¡ íŠ¸ì—”ë“œ í˜•ì‹ìœ¼ë¡œ ë³€í™˜
      const formattedResults = results.results.map(result => ({
        productId: result.productId,
        sentiment: {
          positive: result.sentimentPositive,
          negative: result.sentimentNegative,
          neutral: result.sentimentNeutral,
        },
        summary: result.summary,
        totalReviews: result.totalReviews,
        averageRating: result.averageRating,
        createdAt: result.createdAt,
      }));

      return {
        results: formattedResults,
        pagination: results.pagination,
      };

    } catch (error) {
      console.error('âŒ Failed to get user analysis results:', error);
      throw error;
    }
  }

  /**
   * ë‹¤ì¤‘ ìƒí’ˆ ë¶„ì„ ìš”ì²­ (ê²€ìƒ‰ì–´ ê¸°ë°˜)
   * @param {Object} params - ë¶„ì„ ìš”ì²­ íŒŒë¼ë¯¸í„°
   * @param {string} params.searchQuery - ê²€ìƒ‰ì–´
   * @param {string} params.userId - ì‚¬ìš©ì ID
   * @param {number} params.maxProducts - ìµœëŒ€ ìƒí’ˆ ìˆ˜
   * @returns {Promise<Object>} ë¶„ì„ ìš”ì²­ ê²°ê³¼
   */
  async requestMultiProductAnalysis(params) {
    try {
      const { searchQuery, userId, maxProducts = 10 } = params;
      
      console.log(`ğŸ” Starting multi product analysis request:`, {
        searchQuery,
        userId,
        maxProducts,
      });

      // ì¤‘ë³µ ìš”ì²­ ì²´í¬
      const cacheKey = `analysis:multi:${searchQuery}:${userId}`;
      const existingRequest = await cacheService.get(cacheKey);
      
      if (existingRequest) {
        console.log(`âš¡ Found existing analysis request for search "${searchQuery}"`);
        return {
          status: 'in_progress',
          dagRunId: existingRequest.dagRunId,
          message: 'Analysis already in progress',
          cached: true,
        };
      }

      // Airflow DAG íŠ¸ë¦¬ê±°
      const dagRun = await airflowClient.triggerMultiProductAnalysis({
        searchQuery,
        userId,
        maxProducts,
      });

      // ìš”ì²­ ì •ë³´ ìºì‹œì— ì €ì¥ (30ë¶„ TTL)
      const requestInfo = {
        dagId: dagRun.dagId,
        dagRunId: dagRun.dagRunId,
        searchQuery,
        userId,
        maxProducts,
        status: 'triggered',
        createdAt: new Date().toISOString(),
      };
      
      await cacheService.set(cacheKey, requestInfo, 1800); // 30ë¶„

      // Kafkaë¡œ ë¶„ì„ ì‹œì‘ ë©”ì‹œì§€ ì „ì†¡ (í˜„ì¬ ì‚¬ìš©í•˜ì§€ ì•ŠìŒ)
      // await kafkaProducer.sendMessage('analysis-requests', {
      //   type: 'multi_product_analysis_started',
      //   dagRunId: dagRun.dagRunId,
      //   searchQuery,
      //   userId,
      //   maxProducts,
      //   timestamp: new Date().toISOString(),
      // });

      console.log(`âœ… Multi product analysis triggered successfully:`, {
        dagRunId: dagRun.dagRunId,
        searchQuery,
      });

      return {
        status: 'triggered',
        dagRunId: dagRun.dagRunId,
        dagId: dagRun.dagId,
        executionDate: dagRun.executionDate,
        message: 'Analysis started successfully',
      };

    } catch (error) {
      console.error('âŒ Failed to request multi product analysis:', error);
      
      Sentry.withScope((scope) => {
        scope.setTag('analysis_request_failed', true);
        scope.setContext('analysis_request', {
          type: 'multi_product',
          searchQuery: params.searchQuery,
          userId: params.userId,
        });
        Sentry.captureException(error);
      });

      throw error;
    }
  }

  /**
   * ê´€ì‹¬ ìƒí’ˆ ë°°ì¹˜ ë¶„ì„ ìš”ì²­
   * @param {Object} params - ë¶„ì„ ìš”ì²­ íŒŒë¼ë¯¸í„°
   * @param {string} params.userId - ì‚¬ìš©ì ID
   * @param {Array} params.productIds - ê´€ì‹¬ ìƒí’ˆ ID ëª©ë¡
   * @returns {Promise<Object>} ë¶„ì„ ìš”ì²­ ê²°ê³¼
   */
  async requestWatchlistAnalysis(params) {
    try {
      const { userId, productIds } = params;
      
      console.log(`ğŸ” Starting watchlist analysis request:`, {
        userId,
        productCount: productIds.length,
      });

      // ì¤‘ë³µ ìš”ì²­ ì²´í¬
      const cacheKey = `analysis:watchlist:${userId}`;
      const existingRequest = await cacheService.get(cacheKey);
      
      if (existingRequest) {
        console.log(`âš¡ Found existing watchlist analysis request for user ${userId}`);
        return {
          status: 'in_progress',
          dagRunId: existingRequest.dagRunId,
          message: 'Watchlist analysis already in progress',
          cached: true,
        };
      }

      // Airflow DAG íŠ¸ë¦¬ê±°
      const dagRun = await airflowClient.triggerWatchlistAnalysis({
        userId,
        productIds,
      });

      // ìš”ì²­ ì •ë³´ ìºì‹œì— ì €ì¥ (1ì‹œê°„ TTL)
      const requestInfo = {
        dagId: dagRun.dagId,
        dagRunId: dagRun.dagRunId,
        userId,
        productIds,
        status: 'triggered',
        createdAt: new Date().toISOString(),
      };
      
      await cacheService.set(cacheKey, requestInfo, 3600); // 1ì‹œê°„

      // Kafkaë¡œ ë¶„ì„ ì‹œì‘ ë©”ì‹œì§€ ì „ì†¡ (í˜„ì¬ ì‚¬ìš©í•˜ì§€ ì•ŠìŒ)
      // await kafkaProducer.sendMessage('analysis-requests', {
      //   type: 'watchlist_analysis_started',
      //   dagRunId: dagRun.dagRunId,
      //   userId,
      //   productIds,
      //   timestamp: new Date().toISOString(),
      // });

      console.log(`âœ… Watchlist analysis triggered successfully:`, {
        dagRunId: dagRun.dagRunId,
        userId,
        productCount: productIds.length,
      });

      return {
        status: 'triggered',
        dagRunId: dagRun.dagRunId,
        dagId: dagRun.dagId,
        executionDate: dagRun.executionDate,
        message: 'Watchlist analysis started successfully',
      };

    } catch (error) {
      console.error('âŒ Failed to request watchlist analysis:', error);
      
      Sentry.withScope((scope) => {
        scope.setTag('analysis_request_failed', true);
        scope.setContext('analysis_request', {
          type: 'watchlist',
          userId: params.userId,
          productCount: params.productIds.length,
        });
        Sentry.captureException(error);
      });

      throw error;
    }
  }

  /**
   * ë¶„ì„ ìƒíƒœ ì¡°íšŒ
   * @param {string} dagId - DAG ID
   * @param {string} dagRunId - DAG Run ID
   * @returns {Promise<Object>} ë¶„ì„ ìƒíƒœ ì •ë³´
   */
  async getAnalysisStatus(dagId, dagRunId) {
    try {
      console.log(`ğŸ” Getting analysis status: ${dagId}/${dagRunId}`);

      // ìºì‹œì—ì„œ ê¸°ë³¸ ì •ë³´ ì¡°íšŒ
      const cacheKey = `status:${dagId}:${dagRunId}`;
      const cachedStatus = await cacheService.get(cacheKey);

      // Airflowì—ì„œ ìµœì‹  ìƒíƒœ ì¡°íšŒ
      const dagRunStatus = await airflowClient.getDagRunStatus(dagId, dagRunId);
      const tasks = await airflowClient.getDagRunTasks(dagId, dagRunId);

      const result = {
        dagId,
        dagRunId,
        state: dagRunStatus.state,
        executionDate: dagRunStatus.executionDate,
        startDate: dagRunStatus.startDate,
        endDate: dagRunStatus.endDate,
        tasks: tasks,
        progress: this.calculateProgress(tasks),
        cached: !!cachedStatus,
      };

      // ìƒíƒœ ì •ë³´ ìºì‹œ (5ë¶„ TTL)
      await cacheService.set(cacheKey, result, 300);

      console.log(`ğŸ“Š Analysis status retrieved:`, {
        dagRunId,
        state: result.state,
        progress: result.progress,
      });

      return result;

    } catch (error) {
      console.error('âŒ Failed to get analysis status:', error);
      
      Sentry.withScope((scope) => {
        scope.setTag('analysis_status_check_failed', true);
        scope.setContext('analysis_status_check', {
          dagId,
          dagRunId,
        });
        Sentry.captureException(error);
      });

      throw error;
    }
  }

  /**
   * íƒœìŠ¤í¬ ì§„í–‰ë¥  ê³„ì‚°
   * @param {Array} tasks - íƒœìŠ¤í¬ ëª©ë¡
   * @returns {Object} ì§„í–‰ë¥  ì •ë³´
   */
  calculateProgress(tasks) {
    const totalTasks = tasks.length;
    const completedTasks = tasks.filter(task => task.state === 'success').length;
    const failedTasks = tasks.filter(task => task.state === 'failed').length;
    const runningTasks = tasks.filter(task => task.state === 'running').length;

    return {
      total: totalTasks,
      completed: completedTasks,
      failed: failedTasks,
      running: runningTasks,
      percentage: totalTasks > 0 ? Math.round((completedTasks / totalTasks) * 100) : 0,
    };
  }

  /**
   * í™œì„± ë¶„ì„ ëª©ë¡ ì¡°íšŒ
   * @param {string} userId - ì‚¬ìš©ì ID
   * @returns {Promise<Array>} í™œì„± ë¶„ì„ ëª©ë¡
   */
  async getActiveAnalyses(userId) {
    try {
      console.log(`ğŸ” Getting active analyses for user: ${userId}`);

      // ìºì‹œì—ì„œ ì‚¬ìš©ìì˜ í™œì„± ë¶„ì„ ëª©ë¡ ì¡°íšŒ
      const cachePattern = `analysis:*:*:${userId}`;
      const activeAnalyses = [];

      // ì‹¤ì œ êµ¬í˜„ì—ì„œëŠ” Redis SCANì„ ì‚¬ìš©í•˜ê±°ë‚˜ ë³„ë„ ì¸ë±ìŠ¤ ê´€ë¦¬ í•„ìš”
      // ì—¬ê¸°ì„œëŠ” ê°„ë‹¨í•œ ì˜ˆì‹œë¡œ êµ¬í˜„

      console.log(`ğŸ“‹ Found ${activeAnalyses.length} active analyses for user ${userId}`);
      
      return activeAnalyses;

    } catch (error) {
      console.error('âŒ Failed to get active analyses:', error);
      
      Sentry.withScope((scope) => {
        scope.setTag('active_analyses_check_failed', true);
        scope.setContext('active_analyses_check', { userId });
        Sentry.captureException(error);
      });

      throw error;
    }
  }
}

module.exports = new AnalysisService();